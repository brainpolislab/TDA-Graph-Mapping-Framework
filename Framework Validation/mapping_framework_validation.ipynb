{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import random\n",
    "\n",
    "# TDA\n",
    "import kmapper as km\n",
    "import dyneusr as dsr\n",
    "from sklearn.manifold import Isomap\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.cluster import DBSCAN\n",
    "from kmapper.cover import Cover\n",
    "from tmap.tda.utils import optimize_dbscan_eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "seed_value = 27\n",
    "random.seed(seed_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. Import data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Users/stefanovannoni/Library/CloudStorage/OneDrive-PolitecnicodiMilano/Dottorato/Tesi Magistrale/data.csv'\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Remove class labels\n",
    "x = data.drop('study_group', axis=1)\n",
    "\n",
    "# Class labels\n",
    "y = data['study_group']\n",
    "y_dummy = pd.get_dummies(y)\n",
    "y_dummy = y_dummy.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Class labels histogram\n",
    "labels_freq = data['study_group'].value_counts()\n",
    "colors = ['blue', 'green', 'red', 'orange']\n",
    "labels_freq.plot(kind='bar', color=colors)\n",
    "\n",
    "for i, valore in enumerate(labels_freq):\n",
    "    plt.text(i, valore, str(valore), ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only HC samples\n",
    "x_hc = data[data['study_group'] == 'HC']\n",
    "x_hc = x_hc.drop('study_group', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. Project data (Filtering)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "pca = PCA(n_components=2, random_state=seed_value)\n",
    "pca = pca.fit(x_hc)\n",
    "\n",
    "# Isomap\n",
    "isomap = Isomap(n_components=2)\n",
    "isomap = isomap.fit(x_hc)\n",
    "\n",
    "# Kernel PCA\n",
    "kernelpca = KernelPCA(n_components=2, kernel='rbf', random_state=seed_value)\n",
    "kernelpca = kernelpca.fit(x_hc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Projection into 2D\n",
    "x_hc_pca = pca.transform(x_hc)\n",
    "x_hc_isomap = isomap.transform(x_hc)\n",
    "x_hc_kernelpca = kernelpca.transform(x_hc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **4. TDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeplerMapper()\n"
     ]
    }
   ],
   "source": [
    "mapper = km.KeplerMapper(verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..Composing projection pipeline of length 1:\n",
      "\tProjections: [0, 1]\n",
      "\tDistance matrices: False\n",
      "\tScalers: MinMaxScaler()\n",
      "..Projecting on data shaped (251, 2)\n",
      "\n",
      "..Projecting data using: [0, 1]\n",
      "\n",
      "..Scaling with: MinMaxScaler()\n",
      "\n",
      "..Composing projection pipeline of length 1:\n",
      "\tProjections: [0, 1]\n",
      "\tDistance matrices: False\n",
      "\tScalers: MinMaxScaler()\n",
      "..Projecting on data shaped (251, 2)\n",
      "\n",
      "..Projecting data using: [0, 1]\n",
      "\n",
      "..Scaling with: MinMaxScaler()\n",
      "\n",
      "..Composing projection pipeline of length 1:\n",
      "\tProjections: [0, 1]\n",
      "\tDistance matrices: False\n",
      "\tScalers: MinMaxScaler()\n",
      "..Projecting on data shaped (251, 2)\n",
      "\n",
      "..Projecting data using: [0, 1]\n",
      "\n",
      "..Scaling with: MinMaxScaler()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create lens function\n",
    "lens_pca = mapper.fit_transform(pca.fit_transform(x_hc, y=None), projection=[0,1])\n",
    "lens_isomap = mapper.fit_transform(isomap.fit_transform(x_hc, y=None), projection=[0,1])\n",
    "lens_kernelpca = mapper.fit_transform(kernelpca.fit_transform(x_hc, y=None), projection=[0,1])\n",
    "\n",
    "# Create cover\n",
    "cover = Cover(n_cubes=20, perc_overlap=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping on data shaped (251, 12720) using lens shaped (251, 2)\n",
      "\n",
      "Creating 400 hypercubes.\n",
      "\n",
      "Created 274 edges and 96 nodes in 0:00:00.128273.\n",
      "Mapping on data shaped (251, 12720) using lens shaped (251, 2)\n",
      "\n",
      "Creating 400 hypercubes.\n",
      "\n",
      "Created 348 edges and 138 nodes in 0:00:00.143927.\n",
      "Mapping on data shaped (251, 12720) using lens shaped (251, 2)\n",
      "\n",
      "Creating 400 hypercubes.\n",
      "\n",
      "Created 413 edges and 152 nodes in 0:00:00.139587.\n"
     ]
    }
   ],
   "source": [
    "# Create graph\n",
    "graph_pca = mapper.map(\n",
    "    lens=lens_pca,\n",
    "    X=x_hc,\n",
    "    cover=cover,\n",
    "    clusterer=DBSCAN(eps=optimize_dbscan_eps(x_hc, threshold=95), min_samples=2)\n",
    ")\n",
    "\n",
    "graph_isomap = mapper.map(\n",
    "    lens=lens_isomap,\n",
    "    X=x_hc,\n",
    "    cover=cover,\n",
    "    clusterer=DBSCAN(eps=optimize_dbscan_eps(x_hc, threshold=95), min_samples=2)\n",
    ")\n",
    "\n",
    "graph_kernelpca = mapper.map(\n",
    "    lens=lens_kernelpca,\n",
    "    X=x_hc,\n",
    "    cover=cover,\n",
    "    clusterer=DBSCAN(eps=optimize_dbscan_eps(x_hc, threshold=95), min_samples=2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert graphs to networkx\n",
    "graph_pca_nx = km.adapter.to_nx(graph_pca)\n",
    "graph_isomap_nx = km.adapter.to_nx(graph_isomap)\n",
    "graph_kernelpca_nx = km.adapter.to_nx(graph_kernelpca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "samples_in_nodes_pca = {name: attributes['membership'] for name, attributes in list(graph_pca_nx.nodes(data=True))}\n",
    "samples_in_nodes_pca = list(samples_in_nodes_pca.values())\n",
    "samples_pca = [int(el_pca.split('cube')[1].split('_')[0]) for el_pca in list(graph_pca_nx.nodes())] # node indices (number of nodes of the TDA graph)\n",
    "\n",
    "# Isomap\n",
    "samples_in_nodes_isomap = {name: attributes['membership'] for name, attributes in list(graph_isomap_nx.nodes(data=True))}\n",
    "samples_in_nodes_isomap = list(samples_in_nodes_isomap.values())\n",
    "samples_isomap = [int(el_isomap.split('cube')[1].split('_')[0]) for el_isomap in list(graph_isomap_nx.nodes())] # node indices (number of nodes of the TDA graph)\n",
    "\n",
    "# Kernel PCA\n",
    "samples_in_nodes_kernelpca = {name: attributes['membership'] for name, attributes in list(graph_kernelpca_nx.nodes(data=True))}\n",
    "samples_in_nodes_kernelpca = list(samples_in_nodes_kernelpca.values())\n",
    "samples_kernelpca = [int(el_kernelpca.split('cube')[1].split('_')[0]) for el_kernelpca in list(graph_kernelpca_nx.nodes())] # node indices (number of nodes of the TDA graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **5. Framework validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_tda(data, sample, cover):\n",
    "    # Add index column to data\n",
    "    indices = np.arange(data.shape[0])[:, np.newaxis]\n",
    "    data = np.hstack((indices, data))\n",
    "\n",
    "    # Fit cover and get cube centers\n",
    "    cube_centers = cover.fit(data)\n",
    "    cube_centers = [(sublist[0], sublist[1]) for sublist in cube_centers]\n",
    "\n",
    "    # Transform data into hypercubes\n",
    "    hyper_cubes = cover.transform(data, cube_centers)\n",
    "\n",
    "    # Find indices of cubes containing the sample\n",
    "    index_cubes = cover.find(sample)\n",
    "\n",
    "    # Get indices of matching hypercubes\n",
    "    hyper_cubes_index = []\n",
    "    for index in index_cubes:\n",
    "        cube = cover.transform_single(data, cube_centers[index])\n",
    "\n",
    "        for j in range(len(hyper_cubes)):\n",
    "            if np.array_equal(cube, hyper_cubes[j]):\n",
    "                hyper_cubes_index.append(j)\n",
    "\n",
    "    # Print hypercubes with only one sample\n",
    "    for k in hyper_cubes_index:\n",
    "        if len(hyper_cubes[k]) == 1:\n",
    "            print(f'Hyper cube {k} with only one sample')\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    # Return indices, hypercubes, and centers\n",
    "    return hyper_cubes_index, hyper_cubes, cube_centers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5.1. PCA filter projection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper cube 54 with only one sample\n",
      "Hyper cube 73 with only one sample\n",
      "Hyper cube 74 with only one sample\n",
      "Hyper cube 54 with only one sample\n",
      "Hyper cube 73 with only one sample\n",
      "Hyper cube 74 with only one sample\n",
      "Hyper cube 54 with only one sample\n",
      "Hyper cube 73 with only one sample\n",
      "Hyper cube 74 with only one sample\n",
      "Hyper cube 105 with only one sample\n",
      "Hyper cube 75 with only one sample\n",
      "Hyper cube 91 with only one sample\n",
      "Hyper cube 92 with only one sample\n",
      "Hyper cube 106 with only one sample\n",
      "Hyper cube 107 with only one sample\n",
      "Hyper cube 91 with only one sample\n",
      "Hyper cube 92 with only one sample\n",
      "Hyper cube 106 with only one sample\n",
      "Hyper cube 107 with only one sample\n",
      "Hyper cube 91 with only one sample\n",
      "Hyper cube 92 with only one sample\n",
      "Hyper cube 106 with only one sample\n",
      "Hyper cube 107 with only one sample\n",
      "Hyper cube 91 with only one sample\n",
      "Hyper cube 92 with only one sample\n",
      "Hyper cube 106 with only one sample\n",
      "Hyper cube 107 with only one sample\n",
      "Hyper cube 115 with only one sample\n",
      "Hyper cube 116 with only one sample\n",
      "Hyper cube 117 with only one sample\n",
      "Hyper cube 124 with only one sample\n",
      "Hyper cube 125 with only one sample\n",
      "Hyper cube 116 with only one sample\n",
      "Hyper cube 117 with only one sample\n",
      "Hyper cube 124 with only one sample\n",
      "Hyper cube 125 with only one sample\n",
      "Hyper cube 116 with only one sample\n",
      "Hyper cube 117 with only one sample\n",
      "Hyper cube 124 with only one sample\n",
      "Hyper cube 125 with only one sample\n",
      "Hyper cube 116 with only one sample\n",
      "Hyper cube 117 with only one sample\n",
      "Hyper cube 124 with only one sample\n",
      "Hyper cube 125 with only one sample\n",
      "Hyper cube 88 with only one sample\n",
      "Hyper cube 103 with only one sample\n",
      "Hyper cube 88 with only one sample\n",
      "Hyper cube 103 with only one sample\n",
      "Hyper cube 76 with only one sample\n",
      "Hyper cube 93 with only one sample\n",
      "Hyper cube 76 with only one sample\n",
      "Hyper cube 93 with only one sample\n",
      "Hyper cube 139 with only one sample\n",
      "Hyper cube 140 with only one sample\n",
      "Hyper cube 141 with only one sample\n",
      "Hyper cube 142 with only one sample\n",
      "Hyper cube 139 with only one sample\n",
      "Hyper cube 140 with only one sample\n",
      "Hyper cube 141 with only one sample\n",
      "Hyper cube 142 with only one sample\n",
      "Hyper cube 139 with only one sample\n",
      "Hyper cube 140 with only one sample\n",
      "Hyper cube 141 with only one sample\n",
      "Hyper cube 142 with only one sample\n",
      "Hyper cube 139 with only one sample\n",
      "Hyper cube 140 with only one sample\n",
      "Hyper cube 141 with only one sample\n",
      "Hyper cube 142 with only one sample\n",
      "Hyper cube 14 with only one sample\n",
      "Hyper cube 15 with only one sample\n",
      "Hyper cube 34 with only one sample\n",
      "Hyper cube 14 with only one sample\n",
      "Hyper cube 15 with only one sample\n",
      "Hyper cube 34 with only one sample\n",
      "Hyper cube 14 with only one sample\n",
      "Hyper cube 15 with only one sample\n",
      "Hyper cube 34 with only one sample\n",
      "Hyper cube 143 with only one sample\n",
      "Hyper cube 144 with only one sample\n",
      "Hyper cube 143 with only one sample\n",
      "Hyper cube 144 with only one sample\n",
      "Hyper cube 99 with only one sample\n",
      "Hyper cube 135 with only one sample\n",
      "Hyper cube 136 with only one sample\n",
      "Hyper cube 137 with only one sample\n",
      "Hyper cube 138 with only one sample\n",
      "Hyper cube 135 with only one sample\n",
      "Hyper cube 136 with only one sample\n",
      "Hyper cube 137 with only one sample\n",
      "Hyper cube 138 with only one sample\n",
      "Hyper cube 135 with only one sample\n",
      "Hyper cube 136 with only one sample\n",
      "Hyper cube 137 with only one sample\n",
      "Hyper cube 138 with only one sample\n",
      "Hyper cube 135 with only one sample\n",
      "Hyper cube 136 with only one sample\n",
      "Hyper cube 137 with only one sample\n",
      "Hyper cube 138 with only one sample\n",
      "Hyper cube 126 with only one sample\n",
      "Hyper cube 127 with only one sample\n",
      "Hyper cube 131 with only one sample\n",
      "Hyper cube 132 with only one sample\n",
      "Hyper cube 126 with only one sample\n",
      "Hyper cube 127 with only one sample\n",
      "Hyper cube 131 with only one sample\n",
      "Hyper cube 132 with only one sample\n",
      "Hyper cube 126 with only one sample\n",
      "Hyper cube 127 with only one sample\n",
      "Hyper cube 131 with only one sample\n",
      "Hyper cube 132 with only one sample\n",
      "Hyper cube 126 with only one sample\n",
      "Hyper cube 127 with only one sample\n",
      "Hyper cube 131 with only one sample\n",
      "Hyper cube 132 with only one sample\n",
      "Hyper cube 128 with only one sample\n",
      "Hyper cube 133 with only one sample\n",
      "Hyper cube 134 with only one sample\n",
      "Hyper cube 128 with only one sample\n",
      "Hyper cube 133 with only one sample\n",
      "Hyper cube 134 with only one sample\n",
      "Hyper cube 128 with only one sample\n",
      "Hyper cube 133 with only one sample\n",
      "Hyper cube 134 with only one sample\n",
      "Hyper cube 108 with only one sample\n",
      "Hyper cube 120 with only one sample\n",
      "Hyper cube 121 with only one sample\n",
      "Hyper cube 130 with only one sample\n",
      "Hyper cube 120 with only one sample\n",
      "Hyper cube 121 with only one sample\n",
      "Hyper cube 130 with only one sample\n",
      "Hyper cube 120 with only one sample\n",
      "Hyper cube 121 with only one sample\n",
      "Hyper cube 130 with only one sample\n",
      "Hyper cube 113 with only one sample\n",
      "Hyper cube 122 with only one sample\n",
      "Hyper cube 123 with only one sample\n",
      "Hyper cube 113 with only one sample\n",
      "Hyper cube 122 with only one sample\n",
      "Hyper cube 123 with only one sample\n",
      "Hyper cube 113 with only one sample\n",
      "Hyper cube 122 with only one sample\n",
      "Hyper cube 123 with only one sample\n"
     ]
    }
   ],
   "source": [
    "# Project HC samples\n",
    "sample_map_pca = []\n",
    "check = []\n",
    "\n",
    "for i in range(len(x_hc)):\n",
    "    subject = x_hc.iloc[i, :].values.reshape(1, -1)\n",
    "    subject_pca = pca.transform(subject)\n",
    "    hyper_cubes_index_pca, hyper_cubes_pca, cube_centers_pca = mapping_tda(x_hc_pca, subject_pca, cover)\n",
    "\n",
    "    nodes_indices = []\n",
    "    for k, sample in enumerate(samples_in_nodes_pca):\n",
    "        if i in sample:\n",
    "            nodes_indices.append(samples_pca[k])\n",
    "\n",
    "    if all(index in hyper_cubes_index_pca for index in nodes_indices):\n",
    "        check.append(True)\n",
    "\n",
    "    for cube_index in hyper_cubes_index_pca:\n",
    "        if len(hyper_cubes_pca[cube_index]) > 1:\n",
    "            if cube_index in samples_pca and f'subject_{i}' not in sample_map_pca:\n",
    "                sample_map_pca.append(f'subject_{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "251"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(check).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss_indexes = [f'subject_{i}' for i in range(251) if f'subject_{i}' not in sample_map_pca]\n",
    "miss_indexes = [int(element.split('subject_')[1].split('_')[0]) for element in miss_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "miss_indexes_set = set(miss_indexes)\n",
    "count = sum(valore in sample for sample in samples_in_nodes_pca for valore in miss_indexes_set)\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5.2. Isomap filter projection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper cube 165 with only one sample\n",
      "Hyper cube 166 with only one sample\n",
      "Hyper cube 165 with only one sample\n",
      "Hyper cube 166 with only one sample\n",
      "Hyper cube 76 with only one sample\n",
      "Hyper cube 38 with only one sample\n",
      "Hyper cube 186 with only one sample\n",
      "Hyper cube 43 with only one sample\n",
      "Hyper cube 90 with only one sample\n",
      "Hyper cube 25 with only one sample\n",
      "Hyper cube 26 with only one sample\n",
      "Hyper cube 25 with only one sample\n",
      "Hyper cube 26 with only one sample\n",
      "Hyper cube 97 with only one sample\n",
      "Hyper cube 98 with only one sample\n",
      "Hyper cube 117 with only one sample\n",
      "Hyper cube 118 with only one sample\n",
      "Hyper cube 97 with only one sample\n",
      "Hyper cube 98 with only one sample\n",
      "Hyper cube 117 with only one sample\n",
      "Hyper cube 118 with only one sample\n",
      "Hyper cube 97 with only one sample\n",
      "Hyper cube 98 with only one sample\n",
      "Hyper cube 117 with only one sample\n",
      "Hyper cube 118 with only one sample\n",
      "Hyper cube 97 with only one sample\n",
      "Hyper cube 98 with only one sample\n",
      "Hyper cube 117 with only one sample\n",
      "Hyper cube 118 with only one sample\n",
      "Hyper cube 155 with only one sample\n",
      "Hyper cube 27 with only one sample\n",
      "Hyper cube 181 with only one sample\n",
      "Hyper cube 164 with only one sample\n",
      "Hyper cube 111 with only one sample\n",
      "Hyper cube 167 with only one sample\n",
      "Hyper cube 136 with only one sample\n",
      "Hyper cube 152 with only one sample\n",
      "Hyper cube 136 with only one sample\n",
      "Hyper cube 152 with only one sample\n",
      "Hyper cube 94 with only one sample\n",
      "Hyper cube 114 with only one sample\n",
      "Hyper cube 94 with only one sample\n",
      "Hyper cube 114 with only one sample\n",
      "Hyper cube 200 with only one sample\n",
      "Hyper cube 207 with only one sample\n",
      "Hyper cube 200 with only one sample\n",
      "Hyper cube 207 with only one sample\n",
      "Hyper cube 4 with only one sample\n",
      "Hyper cube 40 with only one sample\n",
      "Hyper cube 7 with only one sample\n",
      "Hyper cube 129 with only one sample\n",
      "Hyper cube 143 with only one sample\n",
      "Hyper cube 96 with only one sample\n",
      "Hyper cube 11 with only one sample\n",
      "Hyper cube 135 with only one sample\n",
      "Hyper cube 151 with only one sample\n",
      "Hyper cube 135 with only one sample\n",
      "Hyper cube 151 with only one sample\n",
      "Hyper cube 119 with only one sample\n",
      "Hyper cube 154 with only one sample\n",
      "Hyper cube 214 with only one sample\n",
      "Hyper cube 77 with only one sample\n",
      "Hyper cube 176 with only one sample\n",
      "Hyper cube 177 with only one sample\n",
      "Hyper cube 187 with only one sample\n",
      "Hyper cube 188 with only one sample\n",
      "Hyper cube 176 with only one sample\n",
      "Hyper cube 177 with only one sample\n",
      "Hyper cube 187 with only one sample\n",
      "Hyper cube 188 with only one sample\n",
      "Hyper cube 176 with only one sample\n",
      "Hyper cube 177 with only one sample\n",
      "Hyper cube 187 with only one sample\n",
      "Hyper cube 188 with only one sample\n",
      "Hyper cube 176 with only one sample\n",
      "Hyper cube 177 with only one sample\n",
      "Hyper cube 187 with only one sample\n",
      "Hyper cube 188 with only one sample\n",
      "Hyper cube 159 with only one sample\n",
      "Hyper cube 12 with only one sample\n",
      "Hyper cube 58 with only one sample\n",
      "Hyper cube 8 with only one sample\n",
      "Hyper cube 24 with only one sample\n",
      "Hyper cube 8 with only one sample\n",
      "Hyper cube 24 with only one sample\n",
      "Hyper cube 212 with only one sample\n",
      "Hyper cube 169 with only one sample\n",
      "Hyper cube 130 with only one sample\n",
      "Hyper cube 205 with only one sample\n",
      "Hyper cube 206 with only one sample\n",
      "Hyper cube 205 with only one sample\n",
      "Hyper cube 206 with only one sample\n",
      "Hyper cube 195 with only one sample\n",
      "Hyper cube 202 with only one sample\n",
      "Hyper cube 209 with only one sample\n",
      "Hyper cube 202 with only one sample\n",
      "Hyper cube 209 with only one sample\n",
      "Hyper cube 203 with only one sample\n",
      "Hyper cube 204 with only one sample\n",
      "Hyper cube 210 with only one sample\n",
      "Hyper cube 211 with only one sample\n",
      "Hyper cube 203 with only one sample\n",
      "Hyper cube 204 with only one sample\n",
      "Hyper cube 210 with only one sample\n",
      "Hyper cube 211 with only one sample\n",
      "Hyper cube 203 with only one sample\n",
      "Hyper cube 204 with only one sample\n",
      "Hyper cube 210 with only one sample\n",
      "Hyper cube 211 with only one sample\n",
      "Hyper cube 203 with only one sample\n",
      "Hyper cube 204 with only one sample\n",
      "Hyper cube 210 with only one sample\n",
      "Hyper cube 211 with only one sample\n",
      "Hyper cube 189 with only one sample\n",
      "Hyper cube 18 with only one sample\n"
     ]
    }
   ],
   "source": [
    "# Project HC samples\n",
    "isomap_sample_map = []\n",
    "check = []\n",
    "\n",
    "for i in range(len(x_hc)):\n",
    "    subject = x_hc.iloc[i, :].values.reshape(1, -1)\n",
    "    subject_isomap = isomap.transform(subject)\n",
    "    hyper_cubes_index_isomap, hyper_cubes_isomap, cube_centers_isomap = mapping_tda(x_hc_isomap, subject_isomap, cover)\n",
    "\n",
    "    nodes_indices = []\n",
    "    for k, sample in enumerate(samples_in_nodes_isomap):\n",
    "        if i in sample:\n",
    "            nodes_indices.append(samples_isomap[k])\n",
    "\n",
    "    if all(index in hyper_cubes_index_isomap for index in nodes_indices):\n",
    "        check.append(True)\n",
    "\n",
    "    for cube_index in hyper_cubes_index_isomap:\n",
    "        if len(hyper_cubes_isomap[cube_index]) > 1:\n",
    "            if cube_index in samples_isomap and f'subject_{i}' not in isomap_sample_map:\n",
    "                isomap_sample_map.append(f'subject_{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "251"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(check).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss_indexes = [f'subject_{i}' for i in range(251) if f'subject_{i}' not in isomap_sample_map]\n",
    "miss_indexes = [int(element.split('subject_')[1].split('_')[0]) for element in miss_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "miss_indexes_set = set(miss_indexes)\n",
    "count = sum(valore in sample for sample in samples_in_nodes_isomap for valore in miss_indexes_set)\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5.3. Kernel PCA filter projection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper cube 183 with only one sample\n",
      "Hyper cube 192 with only one sample\n",
      "Hyper cube 207 with only one sample\n",
      "Hyper cube 192 with only one sample\n",
      "Hyper cube 207 with only one sample\n",
      "Hyper cube 218 with only one sample\n",
      "Hyper cube 86 with only one sample\n",
      "Hyper cube 87 with only one sample\n",
      "Hyper cube 86 with only one sample\n",
      "Hyper cube 87 with only one sample\n",
      "Hyper cube 221 with only one sample\n",
      "Hyper cube 222 with only one sample\n",
      "Hyper cube 229 with only one sample\n",
      "Hyper cube 230 with only one sample\n",
      "Hyper cube 221 with only one sample\n",
      "Hyper cube 222 with only one sample\n",
      "Hyper cube 229 with only one sample\n",
      "Hyper cube 230 with only one sample\n",
      "Hyper cube 221 with only one sample\n",
      "Hyper cube 222 with only one sample\n",
      "Hyper cube 229 with only one sample\n",
      "Hyper cube 230 with only one sample\n",
      "Hyper cube 221 with only one sample\n",
      "Hyper cube 222 with only one sample\n",
      "Hyper cube 229 with only one sample\n",
      "Hyper cube 230 with only one sample\n",
      "Hyper cube 69 with only one sample\n",
      "Hyper cube 83 with only one sample\n",
      "Hyper cube 69 with only one sample\n",
      "Hyper cube 83 with only one sample\n",
      "Hyper cube 155 with only one sample\n",
      "Hyper cube 173 with only one sample\n",
      "Hyper cube 155 with only one sample\n",
      "Hyper cube 173 with only one sample\n",
      "Hyper cube 152 with only one sample\n",
      "Hyper cube 169 with only one sample\n",
      "Hyper cube 170 with only one sample\n",
      "Hyper cube 152 with only one sample\n",
      "Hyper cube 169 with only one sample\n",
      "Hyper cube 170 with only one sample\n",
      "Hyper cube 152 with only one sample\n",
      "Hyper cube 169 with only one sample\n",
      "Hyper cube 170 with only one sample\n",
      "Hyper cube 174 with only one sample\n",
      "Hyper cube 7 with only one sample\n",
      "Hyper cube 8 with only one sample\n",
      "Hyper cube 17 with only one sample\n",
      "Hyper cube 18 with only one sample\n",
      "Hyper cube 7 with only one sample\n",
      "Hyper cube 8 with only one sample\n",
      "Hyper cube 17 with only one sample\n",
      "Hyper cube 18 with only one sample\n",
      "Hyper cube 7 with only one sample\n",
      "Hyper cube 8 with only one sample\n",
      "Hyper cube 17 with only one sample\n",
      "Hyper cube 18 with only one sample\n",
      "Hyper cube 7 with only one sample\n",
      "Hyper cube 8 with only one sample\n",
      "Hyper cube 17 with only one sample\n",
      "Hyper cube 18 with only one sample\n",
      "Hyper cube 178 with only one sample\n",
      "Hyper cube 202 with only one sample\n",
      "Hyper cube 165 with only one sample\n",
      "Hyper cube 166 with only one sample\n",
      "Hyper cube 184 with only one sample\n",
      "Hyper cube 165 with only one sample\n",
      "Hyper cube 166 with only one sample\n",
      "Hyper cube 184 with only one sample\n",
      "Hyper cube 165 with only one sample\n",
      "Hyper cube 166 with only one sample\n",
      "Hyper cube 184 with only one sample\n",
      "Hyper cube 238 with only one sample\n",
      "Hyper cube 239 with only one sample\n",
      "Hyper cube 242 with only one sample\n",
      "Hyper cube 243 with only one sample\n",
      "Hyper cube 238 with only one sample\n",
      "Hyper cube 239 with only one sample\n",
      "Hyper cube 242 with only one sample\n",
      "Hyper cube 243 with only one sample\n",
      "Hyper cube 238 with only one sample\n",
      "Hyper cube 239 with only one sample\n",
      "Hyper cube 242 with only one sample\n",
      "Hyper cube 243 with only one sample\n",
      "Hyper cube 238 with only one sample\n",
      "Hyper cube 239 with only one sample\n",
      "Hyper cube 242 with only one sample\n",
      "Hyper cube 243 with only one sample\n",
      "Hyper cube 197 with only one sample\n",
      "Hyper cube 198 with only one sample\n",
      "Hyper cube 212 with only one sample\n",
      "Hyper cube 213 with only one sample\n",
      "Hyper cube 197 with only one sample\n",
      "Hyper cube 198 with only one sample\n",
      "Hyper cube 212 with only one sample\n",
      "Hyper cube 213 with only one sample\n",
      "Hyper cube 197 with only one sample\n",
      "Hyper cube 198 with only one sample\n",
      "Hyper cube 212 with only one sample\n",
      "Hyper cube 213 with only one sample\n",
      "Hyper cube 197 with only one sample\n",
      "Hyper cube 198 with only one sample\n",
      "Hyper cube 212 with only one sample\n",
      "Hyper cube 213 with only one sample\n",
      "Hyper cube 84 with only one sample\n",
      "Hyper cube 85 with only one sample\n",
      "Hyper cube 101 with only one sample\n",
      "Hyper cube 102 with only one sample\n",
      "Hyper cube 84 with only one sample\n",
      "Hyper cube 85 with only one sample\n",
      "Hyper cube 101 with only one sample\n",
      "Hyper cube 102 with only one sample\n",
      "Hyper cube 84 with only one sample\n",
      "Hyper cube 85 with only one sample\n",
      "Hyper cube 101 with only one sample\n",
      "Hyper cube 102 with only one sample\n",
      "Hyper cube 84 with only one sample\n",
      "Hyper cube 85 with only one sample\n",
      "Hyper cube 101 with only one sample\n",
      "Hyper cube 102 with only one sample\n",
      "Hyper cube 195 with only one sample\n",
      "Hyper cube 196 with only one sample\n",
      "Hyper cube 210 with only one sample\n",
      "Hyper cube 211 with only one sample\n",
      "Hyper cube 195 with only one sample\n",
      "Hyper cube 196 with only one sample\n",
      "Hyper cube 210 with only one sample\n",
      "Hyper cube 211 with only one sample\n",
      "Hyper cube 195 with only one sample\n",
      "Hyper cube 196 with only one sample\n",
      "Hyper cube 210 with only one sample\n",
      "Hyper cube 211 with only one sample\n",
      "Hyper cube 195 with only one sample\n",
      "Hyper cube 196 with only one sample\n",
      "Hyper cube 210 with only one sample\n",
      "Hyper cube 211 with only one sample\n",
      "Hyper cube 56 with only one sample\n",
      "Hyper cube 6 with only one sample\n",
      "Hyper cube 133 with only one sample\n",
      "Hyper cube 164 with only one sample\n",
      "Hyper cube 134 with only one sample\n",
      "Hyper cube 228 with only one sample\n",
      "Hyper cube 16 with only one sample\n",
      "Hyper cube 100 with only one sample\n",
      "Hyper cube 0 with only one sample\n",
      "Hyper cube 1 with only one sample\n",
      "Hyper cube 0 with only one sample\n",
      "Hyper cube 1 with only one sample\n",
      "Hyper cube 187 with only one sample\n",
      "Hyper cube 201 with only one sample\n",
      "Hyper cube 187 with only one sample\n",
      "Hyper cube 201 with only one sample\n",
      "Hyper cube 244 with only one sample\n",
      "Hyper cube 245 with only one sample\n",
      "Hyper cube 244 with only one sample\n",
      "Hyper cube 245 with only one sample\n",
      "Hyper cube 149 with only one sample\n",
      "Hyper cube 150 with only one sample\n",
      "Hyper cube 167 with only one sample\n",
      "Hyper cube 168 with only one sample\n",
      "Hyper cube 149 with only one sample\n",
      "Hyper cube 150 with only one sample\n",
      "Hyper cube 167 with only one sample\n",
      "Hyper cube 168 with only one sample\n",
      "Hyper cube 149 with only one sample\n",
      "Hyper cube 150 with only one sample\n",
      "Hyper cube 167 with only one sample\n",
      "Hyper cube 168 with only one sample\n",
      "Hyper cube 149 with only one sample\n",
      "Hyper cube 150 with only one sample\n",
      "Hyper cube 167 with only one sample\n",
      "Hyper cube 168 with only one sample\n",
      "Hyper cube 235 with only one sample\n",
      "Hyper cube 153 with only one sample\n",
      "Hyper cube 171 with only one sample\n",
      "Hyper cube 153 with only one sample\n",
      "Hyper cube 171 with only one sample\n",
      "Hyper cube 223 with only one sample\n",
      "Hyper cube 224 with only one sample\n",
      "Hyper cube 231 with only one sample\n",
      "Hyper cube 232 with only one sample\n",
      "Hyper cube 223 with only one sample\n",
      "Hyper cube 224 with only one sample\n",
      "Hyper cube 231 with only one sample\n",
      "Hyper cube 232 with only one sample\n",
      "Hyper cube 223 with only one sample\n",
      "Hyper cube 224 with only one sample\n",
      "Hyper cube 231 with only one sample\n",
      "Hyper cube 232 with only one sample\n",
      "Hyper cube 223 with only one sample\n",
      "Hyper cube 224 with only one sample\n",
      "Hyper cube 231 with only one sample\n",
      "Hyper cube 232 with only one sample\n"
     ]
    }
   ],
   "source": [
    "# Project HC samples\n",
    "kernelpca_sample_map = []\n",
    "check = []\n",
    "\n",
    "for i in range(len(x_hc)):\n",
    "    subject = x_hc.iloc[i, :].values.reshape(1, -1)\n",
    "    subject_kernelpca = kernelpca.transform(subject)\n",
    "    hyper_cubes_index_kernelpca, hyper_cubes_kernelpca, cube_centers_kernelpca = mapping_tda(x_hc_kernelpca, subject_kernelpca, cover)\n",
    "\n",
    "    nodes_indices = []\n",
    "    for k, sample in enumerate(samples_in_nodes_kernelpca):\n",
    "        if i in sample:\n",
    "            nodes_indices.append(samples_kernelpca[k])\n",
    "\n",
    "    if all(index in hyper_cubes_index_kernelpca for index in nodes_indices):\n",
    "        check.append(True)\n",
    "\n",
    "    for cube_index in hyper_cubes_index_kernelpca:\n",
    "        if len(hyper_cubes_kernelpca[cube_index]) > 1:\n",
    "            if cube_index in samples_kernelpca and f'subject_{i}' not in kernelpca_sample_map:\n",
    "                kernelpca_sample_map.append(f'subject_{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "251"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(check).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss_indexes = [f'subject_{i}' for i in range(251) if f'subject_{i}' not in kernelpca_sample_map]\n",
    "miss_indexes = [int(element.split('subject_')[1].split('_')[0]) for element in miss_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "miss_indexes_set = set(miss_indexes)\n",
    "count = sum(valore in sample for sample in samples_in_nodes_kernelpca for valore in miss_indexes_set)\n",
    "\n",
    "print(count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mapping framework",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
